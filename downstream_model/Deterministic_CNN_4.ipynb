{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deterministic model is trained based on golden labels(manually labeled), the model takes in one data sample statistics as input and predict the sample label. The input data abstains Context_Specific class. The general accuracy is `94.01`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After prepossessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D, Dropout, concatenate\n",
    "from keras.preprocessing import text as keras_text, sequence as keras_seq\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "np.random.seed(512)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(source+'processed_raw_4.csv')\n",
    "# labels = np.loadtxt('train_marginals.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>y_act</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Attribute_name</th>\n",
       "      <th>Total_val</th>\n",
       "      <th>num_of_dist_val</th>\n",
       "      <th>% nans</th>\n",
       "      <th>max_val</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>sample_5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>p_dist_val</th>\n",
       "      <th>p_nans</th>\n",
       "      <th>castability</th>\n",
       "      <th>extractability</th>\n",
       "      <th>len_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>StratificationCategory2</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058316</td>\n",
       "      <td>0.433625</td>\n",
       "      <td>0.018591</td>\n",
       "      <td>0.489468</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>Stratification2</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>0.451563</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>0.509716</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>StratificationCategory3</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.058316</td>\n",
       "      <td>0.433625</td>\n",
       "      <td>0.018591</td>\n",
       "      <td>0.489468</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>Stratification3</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>0.451563</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>0.509716</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>GeoLocation</td>\n",
       "      <td>403984</td>\n",
       "      <td>55</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(37.63864012300047, -120.99999953799971)</td>\n",
       "      <td>0.090072</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>0.853837</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  y_act Reason           Attribute_name  Total_val  \\\n",
       "0           0             0      3      l  StratificationCategory2     403984   \n",
       "1           1             1      3      l          Stratification2     403984   \n",
       "2           2             2      3      l  StratificationCategory3     403984   \n",
       "3           3             3      3      l          Stratification3     403984   \n",
       "4           4             4      2      c              GeoLocation     403984   \n",
       "\n",
       "   num_of_dist_val    % nans  max_val  mean   ...     \\\n",
       "0                1  0.803648      0.0   0.0   ...      \n",
       "1                1  0.803648      0.0   0.0   ...      \n",
       "2                1  0.803648      0.0   0.0   ...      \n",
       "3                1  0.803648      0.0   0.0   ...      \n",
       "4               55  0.006357      0.0   0.0   ...      \n",
       "\n",
       "                                   sample_5         0         1         2  \\\n",
       "0                                       NaN  0.058316  0.433625  0.018591   \n",
       "1                                       NaN  0.019360  0.451563  0.019360   \n",
       "2                                       NaN  0.058316  0.433625  0.018591   \n",
       "3                                       NaN  0.019360  0.451563  0.019360   \n",
       "4  (37.63864012300047, -120.99999953799971)  0.090072  0.028045  0.853837   \n",
       "\n",
       "          3 p_dist_val    p_nans  castability  extractability  len_val  \n",
       "0  0.489468   0.000002  0.803648            0               0      0.0  \n",
       "1  0.509716   0.000002  0.803648            0               0      0.0  \n",
       "2  0.489468   0.000002  0.803648            0               0      0.0  \n",
       "3  0.509716   0.000002  0.803648            0               0      0.0  \n",
       "4  0.028045   0.000136  0.006357            1               0      2.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_limit(x):\n",
    "    if abs(x) > 10000:\n",
    "        return 10000*np.sign(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(0)\n",
    "data['scaled_mean'] = data['mean'].apply(abs_limit)\n",
    "data['scaled_min_val'] = data['min_val'].apply(abs_limit)\n",
    "data['scaled_max_val'] = data['max_val'].apply(abs_limit)\n",
    "data['scaled_std_dev'] = data['std_dev'].apply(abs_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_to_normalize = ['scaled_max_val', 'scaled_mean', 'scaled_min_val','scaled_std_dev']\n",
    "x = data[column_names_to_normalize].values\n",
    "x = np.nan_to_num(x)\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = data.index)\n",
    "data[column_names_to_normalize] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>y_act</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Attribute_name</th>\n",
       "      <th>Total_val</th>\n",
       "      <th>num_of_dist_val</th>\n",
       "      <th>% nans</th>\n",
       "      <th>max_val</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>p_dist_val</th>\n",
       "      <th>p_nans</th>\n",
       "      <th>castability</th>\n",
       "      <th>extractability</th>\n",
       "      <th>len_val</th>\n",
       "      <th>scaled_mean</th>\n",
       "      <th>scaled_min_val</th>\n",
       "      <th>scaled_max_val</th>\n",
       "      <th>scaled_std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>StratificationCategory2</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489468</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>Stratification2</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509716</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>StratificationCategory3</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489468</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>Stratification3</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509716</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>GeoLocation</td>\n",
       "      <td>403984</td>\n",
       "      <td>55</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028045</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  y_act Reason           Attribute_name  Total_val  \\\n",
       "0           0             0      3      l  StratificationCategory2     403984   \n",
       "1           1             1      3      l          Stratification2     403984   \n",
       "2           2             2      3      l  StratificationCategory3     403984   \n",
       "3           3             3      3      l          Stratification3     403984   \n",
       "4           4             4      2      c              GeoLocation     403984   \n",
       "\n",
       "   num_of_dist_val    % nans  max_val  mean       ...               3  \\\n",
       "0                1  0.803648      0.0   0.0       ...        0.489468   \n",
       "1                1  0.803648      0.0   0.0       ...        0.509716   \n",
       "2                1  0.803648      0.0   0.0       ...        0.489468   \n",
       "3                1  0.803648      0.0   0.0       ...        0.509716   \n",
       "4               55  0.006357      0.0   0.0       ...        0.028045   \n",
       "\n",
       "   p_dist_val    p_nans castability extractability len_val scaled_mean  \\\n",
       "0    0.000002  0.803648           0              0     0.0   -0.289384   \n",
       "1    0.000002  0.803648           0              0     0.0   -0.289384   \n",
       "2    0.000002  0.803648           0              0     0.0   -0.289384   \n",
       "3    0.000002  0.803648           0              0     0.0   -0.289384   \n",
       "4    0.000136  0.006357           1              0     2.0   -0.289384   \n",
       "\n",
       "   scaled_min_val  scaled_max_val  scaled_std_dev  \n",
       "0        0.032129        -0.41314       -0.351573  \n",
       "1        0.032129        -0.41314       -0.351573  \n",
       "2        0.032129        -0.41314       -0.351573  \n",
       "3        0.032129        -0.41314       -0.351573  \n",
       "4        0.032129        -0.41314       -0.351573  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Unnamed: 0.1', 'y_act', 'Reason', 'Attribute_name',\n",
       "       'Total_val', 'num_of_dist_val', '% nans', 'max_val', 'mean', 'min_val',\n",
       "       'std_dev', 'sample_1', 'sample_2', 'sample_3', 'sample_4', 'sample_5',\n",
       "       '0', '1', '2', '3', 'p_dist_val', 'p_nans', 'castability',\n",
       "       'extractability', 'len_val', 'scaled_mean', 'scaled_min_val',\n",
       "       'scaled_max_val', 'scaled_std_dev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 30), (1739, 30))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=100)\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 15), (1739, 15), (6952, 1), (1739, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns =  ['Attribute_name',\n",
    "                  'sample_1',\n",
    "                  'sample_2',\n",
    "                  'sample_3',\n",
    "                  'sample_4',\n",
    "                  'sample_5',\n",
    "                  'p_nans',\n",
    "                  'p_dist_val',\n",
    "                  'scaled_max_val', \n",
    "                  'scaled_mean', \n",
    "                  'scaled_min_val',\n",
    "                  'scaled_std_dev',\n",
    "                  'castability',\n",
    "                  'extractability',\n",
    "                  'len_val']\n",
    "\n",
    "y_columns = ['y_act']\n",
    "\n",
    "X_train = data_train[x_columns].values\n",
    "X_test = data_test[x_columns].values\n",
    "y_train = data_train[y_columns].values.astype(int)\n",
    "y_test = data_test[y_columns].values.astype(int)\n",
    "# y_act = data_test['y_act'].values.astype(int)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_base = 'sample_'\n",
    "# samples_train = []\n",
    "# samples_test = []\n",
    "\n",
    "i = 1\n",
    "field_name = sample_base + str(i)\n",
    "field_idx = x_columns.index(field_name)\n",
    "\n",
    "samples1_train = X_train[:,field_idx].astype(str)\n",
    "samples1_test = X_test[:,field_idx].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = 'Attribute_name'\n",
    "atr_Xtrain = X_train[:,x_columns.index(field_name)].astype(str)\n",
    "atr_Xtest = X_test[:,x_columns.index(field_name)].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "max_features = 128\n",
    "maxlen = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padded_tokens(train_list, test_list, maxlen=maxlen):\n",
    "    tokenizer = keras_text.Tokenizer(char_level = True)\n",
    "    tokenizer.fit_on_texts(train_list)\n",
    "    tokenized_train = tokenizer.texts_to_sequences(train_list)\n",
    "    pad_train = keras_seq.pad_sequences(tokenized_train, maxlen)\n",
    "\n",
    "    tokenized_test = tokenizer.texts_to_sequences(test_list)\n",
    "    pad_test = keras_seq.pad_sequences(tokenized_test, maxlen)\n",
    "    return tokenizer, pad_train, pad_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "atr_tokenizer, atr_pad_train, atr_pad_test = generate_padded_tokens(atr_Xtrain, atr_Xtest)\n",
    "sam_tokenizer, sam_pad_train, sam_pad_test = generate_padded_tokens(samples1_train, samples1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 9), (1739, 9))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_left = X_train[:,6:]\n",
    "X_test_left = X_test[:,6:]\n",
    "X_train_left.shape, X_test_left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 128), (6952, 128), (6952, 9))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = atr_pad_train\n",
    "X_t1 = sam_pad_train\n",
    "structured_data_train = X_train_left\n",
    "X_te = atr_pad_test\n",
    "X_te1 = sam_pad_test\n",
    "structured_data_test = X_test_left\n",
    "X_t.shape, X_t1.shape, structured_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "training starts at: \t 2019-03-07 21:32:05.354997\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print('============================================================')\n",
    "print('training starts at: \\t', datetime.datetime.now())\n",
    "print('============================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 128), (1739, 128), (6952, 4), (1739,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = atr_pad_train\n",
    "X_t1 = sam_pad_train\n",
    "structured_data_train = X_train_left\n",
    "X_te = atr_pad_test\n",
    "X_te1 = sam_pad_test\n",
    "structured_data_test = X_test_left\n",
    "X_t.shape, X_t1.shape, structured_data_train.shape\n",
    "\n",
    "Xtrain = [X_t, X_t1, structured_data_train]\n",
    "Xtest = [X_te, X_te1, structured_data_test]\n",
    "Ytrain = to_categorical(y_train)\n",
    "Ytest = y_test.flatten()\n",
    "X_t.shape, X_te.shape, Ytrain.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://sujitpal.blogspot.com/2018/02/using-snorkel-probabilistic-labels-for.html\n",
    "\n",
    "def build_model(numfilters, embed_size, num_classes, tokenizer1, tokenizer2, maxlen):\n",
    "    # name space input\n",
    "    seq_input = Input(shape=(maxlen,))\n",
    "    x = Embedding(input_dim = len(tokenizer1.word_counts)+1, output_dim = embed_size)(seq_input)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv1D(numfilters*2**(i), kernel_size = 3, activation = 'relu')(x)\n",
    "    out_conv = [Dropout(0.5)(GlobalMaxPool1D()(x)), GlobalMaxPool1D()(x)]\n",
    "    seq1 = concatenate(out_conv, axis = -1)  \n",
    "\n",
    "    # sample space input\n",
    "    seq_input2 = Input(shape=(maxlen, ))\n",
    "    x = Embedding(input_dim = len(tokenizer2.word_counts)+1, output_dim = embed_size)(seq_input2)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv1D(numfilters*2**(i), kernel_size = 3, activation = 'relu')(x)\n",
    "    out_conv = [Dropout(0.5)(GlobalMaxPool1D()(x)), GlobalMaxPool1D()(x)]\n",
    "    seq2 = concatenate(out_conv, axis = -1)\n",
    "\n",
    "    # feature space input\n",
    "    list_input = Input(shape=(9,))\n",
    "\n",
    "    layersfin = keras.layers.concatenate([seq1, seq2, list_input])\n",
    "    x = Dense(500, activation='relu')(layersfin)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(500, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    preds = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=[seq_input,seq_input2,list_input], outputs=[preds])\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fit_model(model, best_model_file, Xtrain, Ytrain, epochs=20, verbose=1):\n",
    "    checkpoint = ModelCheckpoint(filepath=best_model_file,\n",
    "                                 monitor='val_acc', \n",
    "                                 verbose=verbose,\n",
    "                                 save_best_only=True)\n",
    "\n",
    "    early = EarlyStopping(monitor=\"val_acc\", patience=20)\n",
    "    callbacks_list = [checkpoint, early] #early            \n",
    "\n",
    "    history = model.fit(Xtrain, Ytrain, \n",
    "                        validation_split=0.1, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=64,\n",
    "                        verbose=verbose,\n",
    "                        callbacks=callbacks_list)\n",
    "    return history\n",
    "  \n",
    "def eval_report(title, Ytest, Ytest_, prob, verbose=True):\n",
    "    if prob:\n",
    "        ytest = np.argmax(Ytest, axis=1)\n",
    "    else:\n",
    "        ytest = Ytest\n",
    "    ytest_ = Ytest_\n",
    "    acc = accuracy_score(ytest, ytest_)\n",
    "    cm = confusion_matrix(ytest, ytest_)\n",
    "    if verbose:\n",
    "        print(\"\\n*** {:s}\".format(title.upper()))\n",
    "        print(\"accuracy: {:.3f}\".format(acc*100))\n",
    "        print(\"confusion matrix\")\n",
    "        print(cm)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ne=32\n",
    "md=128\n",
    "epoch=50\n",
    "num_classes = Ytrain.shape[1]\n",
    "\n",
    "model_p = build_model(ne, md, num_classes, atr_tokenizer, sam_tokenizer, maxlen)\n",
    "model_p = compile_model(model_p)\n",
    "\n",
    "BEST_MODEL_P = 'best_weights'+str(ne)+str(md)+'.h5'\n",
    "\n",
    "fit_model(model_p, BEST_MODEL_P, Xtrain, Ytrain, epoch, verbose=0)\n",
    "\n",
    "best_model_p = load_model(BEST_MODEL_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** ACC\n",
      "accuracy: 94.077\n",
      "confusion matrix\n",
      "[[408   7   8   8]\n",
      " [ 12 983   4   0]\n",
      " [ 12   3 100   4]\n",
      " [ 34   6   5 145]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9407705577918344"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yptest_ = best_model_p.predict(Xtest)\n",
    "Ytest_ = np.argmax(Yptest_,axis=1)\n",
    "eval_report(\"Acc\", Ytest, Ytest_, prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
