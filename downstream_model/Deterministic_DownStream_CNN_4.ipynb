{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mY_69slzL08-"
   },
   "source": [
    "The deterministic model is trained based on golden labels(manually labeled), the model takes in one data sample statistics as input and predict the sample label. The input data abstains Context_Specific class. The general accuracy is `93.445`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SBunu25pL09A"
   },
   "source": [
    "## After prepossessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XDpKESOxL67f",
    "outputId": "e3ea4b79-616e-477f-9a96-d03e607347fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-675gOlBL09A"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D, Dropout, concatenate\n",
    "from keras.preprocessing import text as keras_text, sequence as keras_seq\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "np.random.seed(512)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.utils import to_categorical\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TynLdIycL09D"
   },
   "outputs": [],
   "source": [
    "# base = 'drive/My Drive/snow/downsteam_model/'\n",
    "source = './../results/'\n",
    "data = pd.read_csv(source+'processed_raw_4.csv')\n",
    "labels = pd.read_csv(source+'train_marginals_4.csv',header=None).values\n",
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "_0W8cCo_L09G",
    "outputId": "9d9ce09f-9064-4833-9a60-5177f14a3b11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>y_act</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Attribute_name</th>\n",
       "      <th>Total_val</th>\n",
       "      <th>num_of_dist_val</th>\n",
       "      <th>% nans</th>\n",
       "      <th>max_val</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>sample_5</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>p_dist_val</th>\n",
       "      <th>p_nans</th>\n",
       "      <th>castability</th>\n",
       "      <th>extractability</th>\n",
       "      <th>len_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>StratificationCategory2</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.785551</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>Stratification2</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.785551</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>StratificationCategory3</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.785551</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>Stratification3</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.071483</td>\n",
       "      <td>0.785551</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>GeoLocation</td>\n",
       "      <td>403984</td>\n",
       "      <td>55</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>(37.63864012300047, -120.99999953799971)</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>0.027548</td>\n",
       "      <td>0.848974</td>\n",
       "      <td>0.027548</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  y_act Reason           Attribute_name  Total_val  \\\n",
       "0           0             0      3      l  StratificationCategory2     403984   \n",
       "1           1             1      3      l          Stratification2     403984   \n",
       "2           2             2      3      l  StratificationCategory3     403984   \n",
       "3           3             3      3      l          Stratification3     403984   \n",
       "4           4             4      2      c              GeoLocation     403984   \n",
       "\n",
       "   num_of_dist_val    % nans  max_val  mean   ...     \\\n",
       "0                1  0.803648      0.0   0.0   ...      \n",
       "1                1  0.803648      0.0   0.0   ...      \n",
       "2                1  0.803648      0.0   0.0   ...      \n",
       "3                1  0.803648      0.0   0.0   ...      \n",
       "4               55  0.006357      0.0   0.0   ...      \n",
       "\n",
       "                                   sample_5         0         1         2  \\\n",
       "0                                       NaN  0.071483  0.071483  0.071483   \n",
       "1                                       NaN  0.071483  0.071483  0.071483   \n",
       "2                                       NaN  0.071483  0.071483  0.071483   \n",
       "3                                       NaN  0.071483  0.071483  0.071483   \n",
       "4  (37.63864012300047, -120.99999953799971)  0.095930  0.027548  0.848974   \n",
       "\n",
       "          3 p_dist_val    p_nans  castability  extractability  len_val  \n",
       "0  0.785551   0.000002  0.803648            0               0      0.0  \n",
       "1  0.785551   0.000002  0.803648            0               0      0.0  \n",
       "2  0.785551   0.000002  0.803648            0               0      0.0  \n",
       "3  0.785551   0.000002  0.803648            0               0      0.0  \n",
       "4  0.027548   0.000136  0.006357            1               0      2.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aG6tadS_L09K"
   },
   "outputs": [],
   "source": [
    "def abs_limit(x):\n",
    "    if abs(x) > 10000:\n",
    "        return 10000*np.sign(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gws0GXtbL09M"
   },
   "outputs": [],
   "source": [
    "data = data.fillna(0)\n",
    "data['scaled_mean'] = data['mean'].apply(abs_limit)\n",
    "data['scaled_min_val'] = data['min_val'].apply(abs_limit)\n",
    "data['scaled_max_val'] = data['max_val'].apply(abs_limit)\n",
    "data['scaled_std_dev'] = data['std_dev'].apply(abs_limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4wIGcWfL09O"
   },
   "outputs": [],
   "source": [
    "column_names_to_normalize = ['scaled_max_val', 'scaled_mean', 'scaled_min_val','scaled_std_dev']\n",
    "x = data[column_names_to_normalize].values\n",
    "x = np.nan_to_num(x)\n",
    "x_scaled = StandardScaler().fit_transform(x)\n",
    "df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index = data.index)\n",
    "data[column_names_to_normalize] = df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "colab_type": "code",
    "id": "df6Sf8y6L09Q",
    "outputId": "cb16243d-2367-44f9-8013-20274f717a6c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>y_act</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Attribute_name</th>\n",
       "      <th>Total_val</th>\n",
       "      <th>num_of_dist_val</th>\n",
       "      <th>% nans</th>\n",
       "      <th>max_val</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>3</th>\n",
       "      <th>p_dist_val</th>\n",
       "      <th>p_nans</th>\n",
       "      <th>castability</th>\n",
       "      <th>extractability</th>\n",
       "      <th>len_val</th>\n",
       "      <th>scaled_mean</th>\n",
       "      <th>scaled_min_val</th>\n",
       "      <th>scaled_max_val</th>\n",
       "      <th>scaled_std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>StratificationCategory2</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785551</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>Stratification2</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785551</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>StratificationCategory3</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785551</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>Stratification3</td>\n",
       "      <td>403984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785551</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.803648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>GeoLocation</td>\n",
       "      <td>403984</td>\n",
       "      <td>55</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027548</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.289384</td>\n",
       "      <td>0.032129</td>\n",
       "      <td>-0.41314</td>\n",
       "      <td>-0.351573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  y_act Reason           Attribute_name  Total_val  \\\n",
       "0           0             0      3      l  StratificationCategory2     403984   \n",
       "1           1             1      3      l          Stratification2     403984   \n",
       "2           2             2      3      l  StratificationCategory3     403984   \n",
       "3           3             3      3      l          Stratification3     403984   \n",
       "4           4             4      2      c              GeoLocation     403984   \n",
       "\n",
       "   num_of_dist_val    % nans  max_val  mean       ...               3  \\\n",
       "0                1  0.803648      0.0   0.0       ...        0.785551   \n",
       "1                1  0.803648      0.0   0.0       ...        0.785551   \n",
       "2                1  0.803648      0.0   0.0       ...        0.785551   \n",
       "3                1  0.803648      0.0   0.0       ...        0.785551   \n",
       "4               55  0.006357      0.0   0.0       ...        0.027548   \n",
       "\n",
       "   p_dist_val    p_nans castability extractability len_val scaled_mean  \\\n",
       "0    0.000002  0.803648           0              0     0.0   -0.289384   \n",
       "1    0.000002  0.803648           0              0     0.0   -0.289384   \n",
       "2    0.000002  0.803648           0              0     0.0   -0.289384   \n",
       "3    0.000002  0.803648           0              0     0.0   -0.289384   \n",
       "4    0.000136  0.006357           1              0     2.0   -0.289384   \n",
       "\n",
       "   scaled_min_val  scaled_max_val  scaled_std_dev  \n",
       "0        0.032129        -0.41314       -0.351573  \n",
       "1        0.032129        -0.41314       -0.351573  \n",
       "2        0.032129        -0.41314       -0.351573  \n",
       "3        0.032129        -0.41314       -0.351573  \n",
       "4        0.032129        -0.41314       -0.351573  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "fS88s18WL09T",
    "outputId": "729ddca8-2873-4f00-96e8-08382d873ade"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'y_act', u'Reason', u'Attribute_name',\n",
       "       u'Total_val', u'num_of_dist_val', u'% nans', u'max_val', u'mean',\n",
       "       u'min_val', u'std_dev', u'sample_1', u'sample_2', u'sample_3',\n",
       "       u'sample_4', u'sample_5', u'0', u'1', u'2', u'3', u'p_dist_val',\n",
       "       u'p_nans', u'castability', u'extractability', u'len_val',\n",
       "       u'scaled_mean', u'scaled_min_val', u'scaled_max_val',\n",
       "       u'scaled_std_dev'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uxHPTYR_L09W",
    "outputId": "0f4b38d4-0dc1-4f64-9ace-245f66c4141e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 30), (1739, 30))"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=100)\n",
    "data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UxwMl_bWL09a",
    "outputId": "3179d215-2908-4b53-ce74-c4895a1aa400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 15), (1739, 15), (6952, 4), (1739, 4), (1739,))"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_columns =  ['Attribute_name',\n",
    "                  'sample_1',\n",
    "                  'sample_2',\n",
    "                  'sample_3',\n",
    "                  'sample_4',\n",
    "                  'sample_5',\n",
    "                  'p_nans',\n",
    "                  'p_dist_val',\n",
    "                  'scaled_max_val', \n",
    "                  'scaled_mean', \n",
    "                  'scaled_min_val',\n",
    "                  'scaled_std_dev',\n",
    "                  'castability',\n",
    "                  'extractability',\n",
    "                  'len_val']\n",
    "\n",
    "y_columns = ['0','1','2','3']\n",
    "\n",
    "X_train = data_train[x_columns].values\n",
    "X_test = data_test[x_columns].values\n",
    "y_train = data_train[y_columns].values.astype(float)\n",
    "y_test = data_test[y_columns].values.astype(float)\n",
    "y_act = data_test['y_act'].values.astype(int)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape, y_act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cCiRAJEUL09d"
   },
   "outputs": [],
   "source": [
    "sample_base = 'sample_'\n",
    "# samples_train = []\n",
    "# samples_test = []\n",
    "\n",
    "i = 1\n",
    "field_name = sample_base + str(i)\n",
    "field_idx = x_columns.index(field_name)\n",
    "\n",
    "samples1_train = X_train[:,field_idx].astype(str)\n",
    "samples1_test = X_test[:,field_idx].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAKMykI9L09f"
   },
   "outputs": [],
   "source": [
    "field_name = 'Attribute_name'\n",
    "atr_Xtrain = X_train[:,x_columns.index(field_name)].astype(str)\n",
    "atr_Xtest = X_test[:,x_columns.index(field_name)].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xyhsa4ZqL09k"
   },
   "outputs": [],
   "source": [
    "# define network parameters\n",
    "max_features = 128\n",
    "maxlen = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7ZAAx0dIL09m"
   },
   "outputs": [],
   "source": [
    "def generate_padded_tokens(train_list, test_list, maxlen=maxlen):\n",
    "    tokenizer = keras_text.Tokenizer(char_level = True)\n",
    "    tokenizer.fit_on_texts(train_list)\n",
    "    tokenized_train = tokenizer.texts_to_sequences(train_list)\n",
    "    pad_train = keras_seq.pad_sequences(tokenized_train, maxlen)\n",
    "\n",
    "    tokenized_test = tokenizer.texts_to_sequences(test_list)\n",
    "    pad_test = keras_seq.pad_sequences(tokenized_test, maxlen)\n",
    "    return tokenizer, pad_train, pad_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFtIeULyL09p"
   },
   "outputs": [],
   "source": [
    "atr_tokenizer, atr_pad_train, atr_pad_test = generate_padded_tokens(atr_Xtrain, atr_Xtest)\n",
    "sam_tokenizer, sam_pad_train, sam_pad_test = generate_padded_tokens(samples1_train, samples1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tuTJQJc-L09s",
    "outputId": "e4bfaa8b-d90e-4a23-8691-d9331d3deba4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 9), (1739, 9))"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_left = X_train[:,6:]\n",
    "X_test_left = X_test[:,6:]\n",
    "X_train_left.shape, X_test_left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ggMcfKa3L09w",
    "outputId": "70eeabaa-77d5-4fc3-e905-f737374541c1",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 128), (6952, 128), (6952, 9))"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = atr_pad_train\n",
    "X_t1 = sam_pad_train\n",
    "structured_data_train = X_train_left\n",
    "X_te = atr_pad_test\n",
    "X_te1 = sam_pad_test\n",
    "structured_data_test = X_test_left\n",
    "X_t.shape, X_t1.shape, structured_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "eGME60TxL09z",
    "outputId": "6092022c-1730-419e-d673-24d76e88248b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "('training starts at: \\t', datetime.datetime(2019, 3, 7, 22, 10, 29, 922316))\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print('============================================================')\n",
    "print('training starts at: \\t', datetime.datetime.now())\n",
    "print('============================================================\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FD1dDQH1L093"
   },
   "outputs": [],
   "source": [
    "# http://sujitpal.blogspot.com/2018/02/using-snorkel-probabilistic-labels-for.html\n",
    "\n",
    "def build_model(numfilters, embed_size, num_classes, tokenizer1, tokenizer2, maxlen):\n",
    "    # name space input\n",
    "    seq_input = Input(shape=(maxlen,))\n",
    "    x = Embedding(input_dim = len(tokenizer1.word_counts)+1, output_dim = embed_size)(seq_input)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv1D(numfilters*2**(i), kernel_size = 3, activation = 'relu')(x)\n",
    "    out_conv = [Dropout(0.5)(GlobalMaxPool1D()(x)), GlobalMaxPool1D()(x)]\n",
    "    seq1 = concatenate(out_conv, axis = -1)  \n",
    "\n",
    "    # sample space input\n",
    "    seq_input2 = Input(shape=(maxlen, ))\n",
    "    x = Embedding(input_dim = len(tokenizer2.word_counts)+1, output_dim = embed_size)(seq_input2)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv1D(numfilters*2**(i), kernel_size = 3, activation = 'relu')(x)\n",
    "    out_conv = [Dropout(0.5)(GlobalMaxPool1D()(x)), GlobalMaxPool1D()(x)]\n",
    "    seq2 = concatenate(out_conv, axis = -1)\n",
    "\n",
    "    # feature space input\n",
    "    list_input = Input(shape=(9,))\n",
    "\n",
    "    layersfin = keras.layers.concatenate([seq1, seq2, list_input])\n",
    "    x = Dense(500, activation='relu')(layersfin)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Dense(500, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    \n",
    "    preds = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=[seq_input,seq_input2,list_input], outputs=[preds])\n",
    "    return model\n",
    "\n",
    "def compile_model(model):\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def fit_model(model, best_model_file, Xtrain, Ytrain, epochs=20, verbose=1):\n",
    "    checkpoint = ModelCheckpoint(filepath=best_model_file,\n",
    "                                 monitor='val_acc', \n",
    "                                 verbose=verbose,\n",
    "                                 save_best_only=True)\n",
    "\n",
    "    early = EarlyStopping(monitor=\"val_acc\", patience=20)\n",
    "    callbacks_list = [checkpoint, early] #early            \n",
    "\n",
    "    history = model.fit(Xtrain, Ytrain, \n",
    "                        validation_split=0.1, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=64,\n",
    "                        verbose=verbose,\n",
    "                        callbacks=callbacks_list)\n",
    "    return history\n",
    "  \n",
    "def eval_report(title, Ytest, Ytest_, prob, verbose=True):\n",
    "    if prob:\n",
    "        ytest = np.argmax(Ytest, axis=1)\n",
    "    else:\n",
    "        ytest = Ytest\n",
    "    ytest_ = np.argmax(Ytest_, axis=1)\n",
    "    acc = accuracy_score(ytest, ytest_)\n",
    "    cm = confusion_matrix(ytest, ytest_)\n",
    "    if verbose:\n",
    "      print(\"\\n*** {:s}\".format(title.upper()))\n",
    "      print(\"accuracy: {:.3f}\".format(acc*100))\n",
    "      print(\"confusion matrix\")\n",
    "      print(cm)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "j-Ry_dkeN1-K",
    "outputId": "351ff502-3bf7-4bcf-8302-4e5a09739c47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6952, 128), (1739, 128), (6952, 4), (1739, 4), (1739,))"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t = atr_pad_train\n",
    "X_t1 = sam_pad_train\n",
    "structured_data_train = X_train_left\n",
    "X_te = atr_pad_test\n",
    "X_te1 = sam_pad_test\n",
    "structured_data_test = X_test_left\n",
    "X_t.shape, X_t1.shape, structured_data_train.shape\n",
    "\n",
    "Xtrain = [X_t, X_t1, structured_data_train]\n",
    "Xtest = [X_te, X_te1, structured_data_test]\n",
    "Yptrain = y_train\n",
    "Yptest = y_test\n",
    "Yctest = y_act\n",
    "X_t.shape, X_te.shape, Yptrain.shape, Yptest.shape, Yctest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JFDp2ikQNXIM"
   },
   "outputs": [],
   "source": [
    "nes = [16, 32, 64, 128, 512]\n",
    "mds = [16, 32, 64, 128]\n",
    "epoches = [10, 20, 50, 100]\n",
    "\n",
    "num_classes = Yptrain.shape[1]\n",
    "\n",
    "scores = list()\n",
    "with open(output_base+'log.txt', 'w') as fw:\n",
    "  fw.write('[{:5s} {:5s} {:5s}]  -  {:6s}  -  {:6s}  -  {:6s}'.format('ne', 'md', 'epoch','train','test','real'))\n",
    "  fw.write('\\n')\n",
    "  for i, ne in enumerate(nes):\n",
    "    for j, md in enumerate(mds):\n",
    "      for k, epoch in enumerate(epoches):\n",
    "        model_p = build_model(ne, md, num_classes, atr_tokenizer, sam_tokenizer, maxlen)\n",
    "        model_p = compile_model(model_p)\n",
    "\n",
    "        BEST_MODEL_P = output_base+'best_weights='+\\\n",
    "                        '_ne'+str(ne)+\\\n",
    "                        '_md'+str(md)+\\\n",
    "                        '_ep'+str(epoch)+'.h5'\n",
    "        fit_model(model_p, BEST_MODEL_P, Xtrain, Yptrain, epoch, verbose=0)\n",
    "        best_model_p = load_model(BEST_MODEL_P)\n",
    "        Yptest_ = best_model_p.predict(Xtest)\n",
    "        score0 = eval_report(\"test. probabilistic VS pred. probabilistic\", Yptest, Yptest_, prob=True, verbose=False)\n",
    "        score1 = eval_report(\"test. categorical VS pred. probabilistic\", Yctest, Yptest_, prob=False, verbose=False)\n",
    "        score2 = eval_report(\"test. categorical VS test. probabilistic\", Yctest, Yptest, prob=False, verbose=False)\n",
    "        scores.append((ne, md, epoch, score0, score1, score2))\n",
    "        print('[%5d %5d %5d]\\t' % (ne, md, epoch), 'Disc. Model Acc.: ', round(score1*100,2))\n",
    "        fw.write('[{:5d} {:5d} {:5d}]  -    {:.2f}  -    {:.2f}  -    {:.2f}'.format(ne, md, epoch,\n",
    "                                                                               round(score0*100,2),\n",
    "                                                                               round(score1*100,2),\n",
    "                                                                               round(score2*100,2)))\n",
    "        fw.write('\\n')\n",
    "        fw.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VX7K7rdnL095"
   },
   "outputs": [],
   "source": [
    "ne=128\n",
    "md=128\n",
    "epoch=20\n",
    "num_classes = Yptrain.shape[1]\n",
    "\n",
    "model_p = build_model(ne, md, num_classes, atr_tokenizer, sam_tokenizer, maxlen)\n",
    "model_p = compile_model(model_p)\n",
    "\n",
    "BEST_MODEL_P = 'best_weights'+str(ne)+str(md)+'.h5'\n",
    "\n",
    "fit_model(model_p, BEST_MODEL_P, Xtrain, Yptrain, epoch, verbose=0)\n",
    "\n",
    "best_model_p = load_model(BEST_MODEL_P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "DSm1p2E5L096",
    "outputId": "c140469b-1510-445c-d554-b5341d396aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** TEST. PROBABILISTIC VS PRED. PROBABILISTIC\n",
      "accuracy: 87.292\n",
      "confusion matrix\n",
      "[[401  89   9   8]\n",
      " [ 22 897   0   8]\n",
      " [ 12  18  53   1]\n",
      " [ 32  14   8 167]]\n",
      "\n",
      "*** TEST. CATEGORICAL VS PRED. PROBABILISTIC\n",
      "accuracy: 84.416\n",
      "confusion matrix\n",
      "[[340  84   1   6]\n",
      " [ 52 921   0  26]\n",
      " [ 40   6  64   9]\n",
      " [ 35   7   5 143]]\n",
      "\n",
      "*** TEST. CATEGORICAL VS TEST. PROBABILISTIC\n",
      "accuracy: 85.509\n",
      "confusion matrix\n",
      "[[374  50   4   3]\n",
      " [ 84 872  16  27]\n",
      " [ 39   2  64  14]\n",
      " [ 10   3   0 177]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8550891316848763"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yptest_ = best_model_p.predict(Xtest)\n",
    "eval_report(\"test. probabilistic VS pred. probabilistic\", Yptest, Yptest_, prob=True)\n",
    "eval_report(\"test. categorical VS pred. probabilistic\", Yctest, Yptest_, prob=False)\n",
    "eval_report(\"test. categorical VS test. probabilistic\", Yctest, Yptest, prob=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNq7_D9ZPiTC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Deterministic_DownStream_CNN_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
